{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3324 images belonging to 5 classes.\n",
      "Found 1423 images belonging to 5 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amr Samir\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  5/104\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 2s/step - accuracy: 0.3644 - loss: 0.1122"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
    "        \n",
    "        cross_entropy = K.binary_crossentropy(y_true, y_pred)\n",
    "        weight = alpha * y_true * K.pow((1 - y_pred), gamma) + (1 - alpha) * (1 - y_true) * K.pow(y_pred, gamma)\n",
    "        loss = weight * cross_entropy\n",
    "        return K.mean(loss)\n",
    "    return loss\n",
    "\n",
    "# Define constants\n",
    "data_dir = 'D:/Datasets/Date & Orange Fruit'\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "# Data augmentation and splitting\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.3  # Split data into training and validation\n",
    ")\n",
    "\n",
    "# Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Model architecture (DenseNet121)\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze base model layers initially\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss=focal_loss(alpha=0.25, gamma=2.0), metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[lr_reducer, early_stopper]\n",
    ")\n",
    "\n",
    "# Fine-tune by unfreezing base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile with a lower learning rate for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=0.000001), loss=focal_loss(alpha=0.25, gamma=2.0), metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune model\n",
    "fine_tune_history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[lr_reducer, early_stopper]\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "Y_true = validation_generator.classes\n",
    "Y_pred = model.predict(validation_generator)\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "conf_matrix = confusion_matrix(Y_true, Y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_true, Y_pred_classes, target_names=class_labels))\n",
    "\n",
    "# ROC Curve and AUC\n",
    "Y_true_binarized = label_binarize(Y_true, classes=np.arange(len(class_labels)))\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(len(class_labels)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_true_binarized[:, i], Y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    plt.plot(fpr[i], tpr[i], label=f'Class {class_labels[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.title('ROC Curve (One-vs-Rest)')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Per-Class Accuracy\n",
    "per_class_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "for i, label in enumerate(class_labels):\n",
    "    print(f\"Accuracy for class {label}: {per_class_accuracy[i] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
